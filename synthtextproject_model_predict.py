# -*- coding: utf-8 -*-
"""SynthTextProject_model_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BQbFu_huC9lqpzUbYxWdvgtrWrKUsvHT
"""

import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, PReLU
from tensorflow.keras.optimizers import Adam, SGD
import os
import h5py
import matplotlib.pyplot as plt
import cv2 as cv
import tensorflow as tf
from tensorflow.keras import regularizers
from math import sqrt
import random
import pickle
import csv
from tensorflow.python.keras import backend as K

# These lines are meant for using the gpu, originally I worked on colab so I did not need them there, I added them just for you
## LIMIT GPU USAGE
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True  # don't pre-allocate memory; allocate as-needed
config.gpu_options.per_process_gpu_memory_fraction = 1  # limit memory to be allocated
K.set_session(tf.compat.v1.Session(config=config)) # create sess w/ above settings

size = 25 # was 25

# This is code from the colab notebook to get the files from google drive
# from google.colab import drive
#
# folder = '/content/drive/MyDrive/SynthTextProject/'
# filePath = f'{folder}/SynthText_test.h5'
# drive.mount('/content/drive/')

filePath = 'SynthText_test.h5'

db = h5py.File(filePath, 'r')
im_names = list(db['data'].keys())

'''
  This function gets an image and returns a tuple (Images, Text)
  Images - Characters individual images cropped by their given bounding box
  Text - The characters themselves as string
'''
def get_characters_from_image(im):
  img = db['data'][im][:]
  txt = db['data'][im].attrs['txt']
  charBB = db['data'][im].attrs['charBB']
  wordBB = db['data'][im].attrs['wordBB']

  chars_images = []
  chars_text = []
  for char in range(len(charBB[0,0,:])):
    # get the four corners' coordinates of the bounding box
    x1,y1 = charBB[0,0,char],charBB[1,0,char]
    x2,y2 = charBB[0,1,char],charBB[1,1,char]
    x3,y3 = charBB[0,2,char],charBB[1,2,char]
    x4,y4 = charBB[0,3,char],charBB[1,3,char]

    # get the min and max so we can crop them
    # basically get the bounding rectangle of the bounding box that is parallel to the axes
    x_min = int(min([x1,x2,x3,x4]))
    x_max = int(max([x1,x2,x3,x4]))

    y_min = int(min([y1,y2,y3,y4]))
    y_max = int(max([y1,y2,y3,y4]))

    # some coordinates are exceeding a little from the screen
    if y_min < 0:
      y_min = 0
    if x_min < 0:
      x_min = 0

    chars_images.append(img[y_min:y_max,x_min:x_max,:]) # crop the image
    chars_text.append([chr(character) for word in txt for character in word][char])
  return chars_images, chars_text

x = [] # characters images
x_text = [] # characters(as string)
x_names = [] # image's names from which the characters are

# extract characters from all images
for i in range(len(im_names)):
  chars_images, chars_text = get_characters_from_image(im_names[i])
  x.extend(chars_images)
  x_text.extend(chars_text)
  x_names.extend([im_names[i]]*len(chars_images))

x = np.array(x)

# convert every image to uint8 numpy array and scale them to same size
for i in range(len(x)):
  img = np.array(x[i], dtype='uint8')
  img = cv.resize(img,(size,size),interpolation=cv.INTER_CUBIC)
  shape = np.shape(img)
  x[i] = np.copy(img)

# array of the possible fonts with the same indices order as trained on the neural network on the other file
labels = np.array(['Roboto','Ubuntu Mono','Russo One','Raleway','Michroma','Alex Brush', 'Open Sans'])

# normalize the images so they have the same shape as trained on the neural network
for i in range(len(x)):
  img = np.array(x[i], dtype='float32')
  img = img / 255
  x[i] = img

x = np.stack(x, axis=0)

# this is the lines for loading the pickle file, it did not work on windows machine so I wrote the line to load an h5 file which does work :)
# load the neural network model into memory
#f = open(f'model_pickle_80', 'rb')
mp = tf.keras.models.load_model('model_h5_80.h5')
#f.close()

# # uncomment to print the structure of the neural network
# print(mp.summary())

# predict the fonts of the characters' images

y = mp.predict(x)

'''
  This function maps each prediction into the predicted label.
  Each prediction is an array of size 7 (cell for each font predicted) with the probability of the image being this specific font
  Transofrm this prediction to the predicted font(The one with the highest probabilty)
'''
def label_mapping(predict_arr):
  return labels[np.argmax(predict_arr)]

y_labeled = list(map(label_mapping, y))

# These are the fonts in the same shape and order as we need to output to the csv file
fonts = [b'Raleway', b'Open Sans', b'Roboto', b'Ubuntu Mono', b'Michroma', b'Alex Brush', b'Russo One']
# These are the headers of the csv file
headers = [' ','image', 'char'] + fonts

'''
    This function maps each predicted labeled font into a dictionary.
    Each key is a font from the 'fonts' list
    Each value is 0 or 1 depending on which font it actually is
'''
def output_mapping(predicted_font):
  return dict((h,1 if h.decode("utf-8")==predicted_font else 0) for h in fonts)


# create a new csv file
with open(f'results.csv', 'w', newline='') as f:
  # create a csv writer that writes the dictionary from the output_mapping functuon
  writer = csv.DictWriter(f, fieldnames=headers)

  # write the headers of the file
  writer.writeheader()

  # for each font we write his own row
  for i in range(len(y_labeled)):
    # binary results
    row_dict = output_mapping(y_labeled[i])

    # image name
    row_dict['image'] = x_names[i]

    # character in the image
    row_dict['char'] = x_text[i]

    # index number
    row_dict[' '] = i

    # write the entire row
    writer.writerow(row_dict)